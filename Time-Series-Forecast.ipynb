{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas_ods_reader import read_ods\n",
    "from  matplotlib.ticker import PercentFormatter\n",
    "import seaborn as sns\n",
    " \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    " \n",
    "from sklearn import set_config\n",
    "# set_config(display='diagram') # Để trực quan hóa pipeline\n",
    " \n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_excel('data/RTAs_2012_2018_Time_Series.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = pd.read_excel('data/Road Safety Data - Accidents 2019.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(959847, 32)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df_1.append(df_2,ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1077383 entries, 0 to 1077382\n",
      "Data columns (total 32 columns):\n",
      " #   Column                                       Non-Null Count    Dtype  \n",
      "---  ------                                       --------------    -----  \n",
      " 0   Accident_Index                               1077383 non-null  object \n",
      " 1   Location_Easting_OSGR                        1077247 non-null  float64\n",
      " 2   Location_Northing_OSGR                       1077247 non-null  float64\n",
      " 3   Longitude                                    1077237 non-null  float64\n",
      " 4   Latitude                                     1077237 non-null  float64\n",
      " 5   Police_Force                                 1077383 non-null  int64  \n",
      " 6   Accident_Severity                            1077383 non-null  int64  \n",
      " 7   Number_of_Vehicles                           1077383 non-null  int64  \n",
      " 8   Number_of_Casualties                         1077383 non-null  int64  \n",
      " 9   Date                                         1077383 non-null  object \n",
      " 10  Day_of_Week                                  1077383 non-null  int64  \n",
      " 11  Time                                         1077271 non-null  object \n",
      " 12  Local_Authority_(District)                   1077383 non-null  int64  \n",
      " 13  Local_Authority_(Highway)                    1077383 non-null  object \n",
      " 14  1st_Road_Class                               1077383 non-null  int64  \n",
      " 15  1st_Road_Number                              1077383 non-null  int64  \n",
      " 16  Road_Type                                    1077383 non-null  int64  \n",
      " 17  Speed_limit                                  1077346 non-null  float64\n",
      " 18  Junction_Detail                              1077383 non-null  int64  \n",
      " 19  Junction_Control                             1077383 non-null  int64  \n",
      " 20  2nd_Road_Class                               1077383 non-null  int64  \n",
      " 21  2nd_Road_Number                              1077383 non-null  int64  \n",
      " 22  Pedestrian_Crossing-Human_Control            1077383 non-null  int64  \n",
      " 23  Pedestrian_Crossing-Physical_Facilities      1077383 non-null  int64  \n",
      " 24  Light_Conditions                             1077383 non-null  int64  \n",
      " 25  Weather_Conditions                           1077383 non-null  int64  \n",
      " 26  Road_Surface_Conditions                      1077383 non-null  int64  \n",
      " 27  Special_Conditions_at_Site                   1077383 non-null  int64  \n",
      " 28  Carriageway_Hazards                          1077383 non-null  int64  \n",
      " 29  Urban_or_Rural_Area                          1077383 non-null  int64  \n",
      " 30  Did_Police_Officer_Attend_Scene_of_Accident  1077383 non-null  int64  \n",
      " 31  LSOA_of_Accident_Location                    1012127 non-null  object \n",
      "dtypes: float64(5), int64(22), object(5)\n",
      "memory usage: 263.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          2012-01-01 00:00:00\n",
       "1          2012-01-01 00:00:00\n",
       "2          2012-01-01 00:00:00\n",
       "3          2012-01-01 00:00:00\n",
       "4          2012-01-01 00:00:00\n",
       "                  ...         \n",
       "1077378             31/12/2019\n",
       "1077379             31/12/2019\n",
       "1077380             31/12/2019\n",
       "1077381             31/12/2019\n",
       "1077382             31/12/2019\n",
       "Name: Date, Length: 1077383, dtype: object"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1['Date'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in df_1['Date']:\n",
    "#     print(str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: Time, dtype: object)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1['Time'][df_1['Date'] == \"2012-01-04 00:00:00\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x['Time'][x['Date'] == '2012-01-04 00:00:00']\n",
    "for ii in df_1['Time'][df_1['Date'] == '2012-01-04 00:00:00']:\n",
    "    if ii == '17:00:00':\n",
    "        print(ii)\n",
    "# x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.to_csv('data/RTAs_2012_2019_Time_Series.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://roadtraffic.dft.gov.uk/api/local-authorities/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1077383, 32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/RTAs_2012_2019_Time_Series.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Accident_Index', 'Location_Easting_OSGR', 'Location_Northing_OSGR',\n",
       "       'Longitude', 'Latitude', 'Police_Force', 'Accident_Severity',\n",
       "       'Number_of_Vehicles', 'Number_of_Casualties', 'Date', 'Day_of_Week',\n",
       "       'Time', 'Local_Authority_(District)', 'Local_Authority_(Highway)',\n",
       "       '1st_Road_Class', '1st_Road_Number', 'Road_Type', 'Speed_limit',\n",
       "       'Junction_Detail', 'Junction_Control', '2nd_Road_Class',\n",
       "       '2nd_Road_Number', 'Pedestrian_Crossing-Human_Control',\n",
       "       'Pedestrian_Crossing-Physical_Facilities', 'Light_Conditions',\n",
       "       'Weather_Conditions', 'Road_Surface_Conditions',\n",
       "       'Special_Conditions_at_Site', 'Carriageway_Hazards',\n",
       "       'Urban_or_Rural_Area', 'Did_Police_Officer_Attend_Scene_of_Accident',\n",
       "       'LSOA_of_Accident_Location'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta bỏ bớt một số cột không cần dùng trong đồ án này:\n",
    "\n",
    "'Accident_Index','Location_Easting_OSGR', 'Location_Northing_OSGR','Longitude', 'Latitude', 'Police_Force', 'Local_Authority_(District)', '1st_Road_Number', '2nd_Road_Number', 'Did_Police_Officer_Attend_Scene_of_Accident', 'LSOA_of_Accident_Location'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2922,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Date'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-48-e54b3d48f40f>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Date'][df['Date'] == date] = date[0:10]\n"
     ]
    }
   ],
   "source": [
    "for date in df['Date'].unique():\n",
    "    if len(date) != 10:\n",
    "        df['Date'][df['Date'] == date] = date[0:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          2012-01-01\n",
       "1          2012-01-01\n",
       "2          2012-01-01\n",
       "3          2012-01-01\n",
       "4          2012-01-01\n",
       "              ...    \n",
       "1077378    31/12/2019\n",
       "1077379    31/12/2019\n",
       "1077380    31/12/2019\n",
       "1077381    31/12/2019\n",
       "1077382    31/12/2019\n",
       "Name: Date, Length: 1077383, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1077383, 32)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x = df.copy()\n",
    "df = x.copy()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.dropna(subset=['Time'])\n",
    "df = df.dropna(subset=['Time']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1077271, 32)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = df['Date'] + ' ' + df['Time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2012-12-03 17:00:00', '2012-12-03 19:00:00'], dtype='datetime64[ns]', freq=None)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(['12/03/2012 17:00', '12-03-2012 19:00'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1352   2012-01-04 17:00:00\n",
       "1353   2012-01-04 17:00:00\n",
       "1354   2012-01-04 17:00:00\n",
       "1355   2012-01-04 17:00:00\n",
       "Name: Date, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Date'][df['Date'] == '2012-01-04 17:00:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv('data/RTAs_2012_2019_Time_Series.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          2012-01-01 00:00:00\n",
       "1          2012-01-01 00:00:00\n",
       "2          2012-01-01 00:00:00\n",
       "3          2012-01-01 00:00:00\n",
       "4          2012-01-01 00:00:00\n",
       "                  ...         \n",
       "1077378             31/12/2019\n",
       "1077379             31/12/2019\n",
       "1077380             31/12/2019\n",
       "1077381             31/12/2019\n",
       "1077382             31/12/2019\n",
       "Name: Date, Length: 1077383, dtype: object"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:00:00\n",
      "17:00:00\n",
      "17:00:00\n",
      "17:00:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1077383, 32)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x['Time'][x['Date'] == '2012-01-04 00:00:00']\n",
    "for ii in x['Time'][x['Date'] == '2012-01-04 00:00:00']:\n",
    "    if ii == '17:00:00':\n",
    "        print(ii)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "for date in x['Date'].unique():\n",
    "    if len(date) != 10:\n",
    "        x['Date'] = x['Date'].replace(date, date[0:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1112    00:01:00\n",
       "1113    00:10:00\n",
       "1114    00:29:00\n",
       "1115    00:31:00\n",
       "1116    00:32:00\n",
       "          ...   \n",
       "1436    22:50:00\n",
       "1437    22:53:00\n",
       "1438    22:56:00\n",
       "1439    23:07:00\n",
       "1440    23:50:00\n",
       "Name: Time, Length: 329, dtype: object"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['Time'][x['Date'] == '2012-01-04']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:00:00\n",
      "17:00:00\n",
      "17:00:00\n",
      "17:00:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1077383, 32)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for ii in x['Time'][x['Date'] == '2012-01-04']:\n",
    "    if ii == '17:00:00':\n",
    "        print(ii)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = df.copy()\n",
    "df = y.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1077271, 32)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sort_values('Date').reset_index(drop=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "try:\n",
    "    response = requests.get(\"https://roadtraffic.dft.gov.uk/api/local-authorities\")\n",
    "    json_pydata = json.loads(response.text)\n",
    "except Exception as error:\n",
    "     print(error)\n",
    "data_json = []\n",
    "if json_pydata['data'] != None:\n",
    "    data_json.extend(json_pydata['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "North West\n"
     ]
    }
   ],
   "source": [
    "for data in data_json:\n",
    "    if data['ons_code'] == 'E08000005':\n",
    "        print(data['region']['name'])\n",
    "# data_json[0]#['ons_code']\n",
    "# data_json[0]['region']['name']\n",
    "# 'E08000005'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['region'] = df['Local_Authority_(Highway)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "E10000016    33277\n",
       "E10000030    28901\n",
       "E10000012    23052\n",
       "E10000014    22492\n",
       "E10000017    22431\n",
       "             ...  \n",
       "EHEATHROW      294\n",
       "S12000013      206\n",
       "S12000027      178\n",
       "S12000023      149\n",
       "E06000053       13\n",
       "Name: region, Length: 207, dtype: int64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['region'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Date'][0].year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "for local in df['region'].unique():\n",
    "    if local in ['S12000043', 'S12000015', 'S12000024', 'S12000009']:\n",
    "        df['region'] = df['region'].replace(local, 'Scotland')\n",
    "    elif local in ['E06000048', 'E08000020']:\n",
    "        df['region'] = df['region'].replace(local, 'North East')\n",
    "    elif local in ['EHEATHROW']:\n",
    "        df['region'] = df['region'].replace(local, 'London')\n",
    "    else:\n",
    "        for data in data_json:\n",
    "            if data['ons_code'] == local:\n",
    "                df['region'] = df['region'].replace(local, data['region']['name'])\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "London                      201634\n",
       "South East                  171294\n",
       "North West                  107442\n",
       "East of England             102614\n",
       "Yorkshire and The Humber     95438\n",
       "West Midlands                91126\n",
       "South West                   85787\n",
       "East Midlands                79609\n",
       "Scotland                     63429\n",
       "Wales                        41292\n",
       "North East                   37606\n",
       "Name: region, dtype: int64"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['region'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xử lý thời gian\n",
    "\n",
    "Ta chuyển 2 cột `Date` và `Time` về thành một cột.\n",
    "\n",
    "Với dataset dùng để huấn luyện, ta tách cột này ra khỏi data\n",
    "\n",
    "## Xử lý kiểu dữ liệu cột\n",
    "\n",
    "Hiện tại một số cột đang có dạng số, nhưng thực ra là dạng categorical, ta chuyển lại về chữ nhờ file `variable_lookup.xls` do chính phủ Anh cung cấp để dễ dàng hiểu dữ liệu và tìm insight hơn.\n",
    "\n",
    "1. Các cột categorical không có thứ tự, ta chuyển lại về chữ cho cả dataframe dùng để tìm insight, lẫn dataframe dùng để huấn luyện model:\n",
    "\n",
    "'Road_Type', 'Junction_Detail', 'Junction_Control', 'Pedestrian_Crossing-Human_Control', 'Pedestrian_Crossing-Physical_Facilities', 'Special_Conditions_at_Site', 'Carriageway_Hazards', 'Local_Authority_(Highway)'\n",
    "\n",
    "2. Các cột dạng categorical có thứ tự: ta chuyển lại về chữ cho dataframe dùng để tìm insight, nhưng giữ nguyên cho dataframe dùng để huấn luyện model:\n",
    "\n",
    "'Accident_Severity', 'Day_of_Week', '1st_Road_Class', '2nd_Road_Class', 'Light_Conditions', 'Weather_Conditions', 'Road_Surface_Conditions', 'Urban_or_Rural_Area'\n",
    "\n",
    "3. Đặc biệt, ta thấy cột 'Local_Authority_(Highway)' có đến 208 giá trị, ta sẽ chuyển các vùng địa phương này thành khu vực (region) nó phụ thuộc vào, để nghiến cứu trên phạm vi lớn hơn, ta có thể chuyển nhờ file API sau:\n",
    "\n",
    "https://roadtraffic.dft.gov.uk/api/local-authorities1\n",
    "\n",
    "Một số ons_code không có trong api này, ta sẽ tra file variable_lookup.xls và chuyển thủ công\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "unordered_cate_cols = ['Road_Type', 'Junction_Detail', \n",
    "                'Junction_Control', 'Pedestrian_Crossing-Human_Control', \n",
    "                'Pedestrian_Crossing-Physical_Facilities',\n",
    "                'Special_Conditions_at_Site', 'Carriageway_Hazards',\n",
    "                      'Local_Authority_(Highway)']\n",
    "        \n",
    "ordered_cate_cols = ['Accident_Severity', 'Day_of_Week', '1st_Road_Class',\n",
    "                             '2nd_Road_Class', 'Light_Conditions', 'Weather_Conditions',\n",
    "                             'Road_Surface_Conditions', 'Urban_or_Rural_Area']\n",
    "\n",
    "nume_cols = ['Number_of_Vehicles', 'Number_of_Casualties', 'Speed_limit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Road_Type',\n",
       " 'Junction_Detail',\n",
       " 'Junction_Control',\n",
       " 'Pedestrian_Crossing-Human_Control',\n",
       " 'Pedestrian_Crossing-Physical_Facilities',\n",
       " 'Special_Conditions_at_Site',\n",
       " 'Carriageway_Hazards',\n",
       " 'Local_Authority_(Highway)',\n",
       " 'region']"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unordered_cate_cols += ['region']\n",
    "\n",
    "unordered_cate_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Accident_Index','Location_Easting_OSGR', 'Location_Northing_OSGR','Longitude', \n",
    "                      'Latitude', 'Police_Force', 'Local_Authority_(District)', '1st_Road_Number', \n",
    "                      '2nd_Road_Number', 'Did_Police_Officer_Attend_Scene_of_Accident',\n",
    "                      'LSOA_of_Accident_Location'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Accident_Severity', 'Number_of_Vehicles', 'Number_of_Casualties',\n",
       "       'Date', 'Day_of_Week', 'Time', 'Local_Authority_(Highway)',\n",
       "       '1st_Road_Class', 'Road_Type', 'Speed_limit', 'Junction_Detail',\n",
       "       'Junction_Control', '2nd_Road_Class',\n",
       "       'Pedestrian_Crossing-Human_Control',\n",
       "       'Pedestrian_Crossing-Physical_Facilities', 'Light_Conditions',\n",
       "       'Weather_Conditions', 'Road_Surface_Conditions',\n",
       "       'Special_Conditions_at_Site', 'Carriageway_Hazards',\n",
       "       'Urban_or_Rural_Area', 'region'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unordered_cate_cols + ordered_cate_cols + nume_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColAdjustBeforeSplitData(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, mode = 'insight'):\n",
    "#         mode = `insight` or `trainning`\n",
    "        self.mode = mode\n",
    "        pass\n",
    "    def fit(self, X_df, y=None):\n",
    "        return self\n",
    "    def transform(self, X_df, y=None):\n",
    "        tf_df = X_df.copy()\n",
    "        \n",
    "        # Bước 1. Bỏ giá trị trùng\n",
    "        \n",
    "        tf_df = tf_df.drop_duplicates(ignore_index = True)\n",
    "        \n",
    "        #Bước 2. Bỏ cột\n",
    "        \n",
    "        tf_df = tf_df.drop(['Accident_Index','Location_Easting_OSGR', 'Location_Northing_OSGR','Longitude', \n",
    "                      'Latitude', 'Police_Force', 'Local_Authority_(District)', '1st_Road_Number', \n",
    "                      '2nd_Road_Number', 'Did_Police_Officer_Attend_Scene_of_Accident',\n",
    "                      'LSOA_of_Accident_Location'],1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Bước 3. Xửa lý datetime\n",
    "        for date in tf_df['Date'].unique():\n",
    "            if len(date) != 10:\n",
    "                tf_df['Date'] = tf_df['Date'].replace(date, date[0:10])\n",
    "                \n",
    "        tf_df = tf_df.dropna(subset=['Time'])\n",
    "        tf_df['Date'] = tf_df['Date'] + ' ' + tf_df['Time']\n",
    "        tf_df['Date'] = pd.to_datetime(tf_df['Date'])\n",
    "        tf_df = tf_df.sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "        tf_df = tf_df.drop(['Time'], 1)      \n",
    "        # Bước 4. Map\n",
    "        # 4.1  Region\n",
    "        # get data\n",
    "        try:\n",
    "            response = requests.get(\"https://roadtraffic.dft.gov.uk/api/local-authorities\")\n",
    "            json_pydata = json.loads(response.text)\n",
    "        except Exception as error:\n",
    "             print(error)\n",
    "        data_json = []\n",
    "        if json_pydata['data'] != None:\n",
    "            data_json.extend(json_pydata['data'])\n",
    "            \n",
    "        # create region column\n",
    "        tf_df['region'] = tf_df['Local_Authority_(Highway)']\n",
    "        \n",
    "        # map local to region\n",
    "        for local in tf_df['region'].unique():\n",
    "            if local in ['S12000043', 'S12000015', 'S12000024', 'S12000009']:\n",
    "                tf_df['region'] = tf_df['region'].replace(local, 'Scotland')\n",
    "            elif local in ['E06000048', 'E08000020']:\n",
    "                tf_df['region'] = tf_df['region'].replace(local, 'North East')\n",
    "            elif local in ['EHEATHROW']:\n",
    "                tf_df['region'] = tf_df['region'].replace(local, 'London')\n",
    "            else:\n",
    "                for data in data_json:\n",
    "                    if data['ons_code'] == local:\n",
    "                        tf_df['region'] = tf_df['region'].replace(local, data['region']['name'])\n",
    "                        break\n",
    "        \n",
    "        # 4.2 map\n",
    "        if self.mode == 'trainning' or self.mode == 'insight':\n",
    "            \n",
    "            for col in unordered_cate_cols:\n",
    "                if col == 'Pedestrian_Crossing-Human_Control':\n",
    "                    name = 'Ped Cross - Human'\n",
    "                elif col == 'Pedestrian_Crossing-Physical_Facilities':\n",
    "                    name = 'Ped Cross - Physical'\n",
    "                else:\n",
    "                    name = col.replace('_',' ')\n",
    "                    \n",
    "                map_df = pd.read_excel('/content/variable_lookup.xlsx',name)\n",
    "                for code in map_df['code']:\n",
    "                    tf_df[col] = tf_df[col].replace(code,map_df[map_df['code'] == code]['label'].values[0])\n",
    "                    \n",
    "        if self.mode == 'insight':\n",
    "            for col in ordered_cate_cols:\n",
    "                if col == 'Weather_Conditions':\n",
    "                    name = 'Weather'\n",
    "                elif col == 'Road_Surface_Conditions':\n",
    "                    name = 'Road Surface'\n",
    "                elif col == 'Urban_or_Rural_Area':\n",
    "                    name = 'Urban Rural'\n",
    "                else:\n",
    "                    name = col.replace('_',' ')\n",
    "                    \n",
    "                map_df = pd.read_excel('/content/variable_lookup.xlsx',name)\n",
    "                for code in map_df['code']:\n",
    "                    tf_df[col] = tf_df[col].replace(code,map_df[map_df['code'] == code]['label'].values[0])\n",
    "                    \n",
    "        # Bước 5. pop date time\n",
    "        \n",
    "        if self.mode == 'trainning':\n",
    "            date_time = tf_df.pop('Date')\n",
    "            return (date_time, tf_df)\n",
    "        else:\n",
    "            return tf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_indices = {name: i for i, name in enumerate(df.columns)}\n",
    "\n",
    "n = len(df)\n",
    "train_df = df[0:int(n*0.7)]\n",
    "val_df = df[int(n*0.7):int(n*0.9)]\n",
    "test_df = df[int(n*0.9):]\n",
    "\n",
    "num_features = df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-bd9c9bd7e815>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcontigency_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcrosstab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Local_Authority_(District)'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Accident_Severity'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcontigency_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'1'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'2'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'3'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_1' is not defined"
     ]
    }
   ],
   "source": [
    "contigency_df = pd.crosstab(df_1['Local_Authority_(District)'], df_1['Accident_Severity'])\n",
    "contigency_df.columns = ['1','2','3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((sum(contigency_df['1']) + sum(contigency_df['2']) + sum(contigency_df['3'])) == df_1.shape[0])\n",
    "contigency_df\n",
    "# df_1.shape\n",
    "# contigency_df.xs('Accident_Severity', level='1', axis=1)\n",
    "# items_df_preprocessed[df_1['Region'] == f'{region}'].groupby('Accident severity')['Accidents'].agg(sum).reset_index(name='Value count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Region_Severity_df = pd.DataFrame({'Region' : [np.nan],'Fatal' : [np.nan],'Serious' : [np.nan],'Slight' : [np.nan], 'Pr(Ai)': [np.nan]})\n",
    "\n",
    "for region in df_1['LSOA_of_Accident_Location'].unique():\n",
    "    x = items_df_preprocessed[df_1['Region'] == f'{region}'].groupby('Accident severity')['Accidents'].agg(sum).reset_index(name='Value count')\n",
    "    y = np.array(x['Value count'])\n",
    "  # y = np.insert(y, 0, 3, axis=0)\n",
    "  # source: https://stackoverflow.com/a/58293212\n",
    "    data_to_append = {}\n",
    "    for i in range(len(Region_Severity_df.columns)):\n",
    "        if(i>=1 and i !=4):\n",
    "            data_to_append[Region_Severity_df.columns[i]] = y[i-1]\n",
    "        elif (i == 4):\n",
    "            data_to_append[Region_Severity_df.columns[i]] = sum(y)\n",
    "            \n",
    "    Region_Severity_df = Region_Severity_df.append(data_to_append, ignore_index = True)\n",
    "\n",
    "Region_Severity_df = Region_Severity_df.drop(0,0)\n",
    "Region_Severity_df['Region'] = RTAs_region_year_df['Region'].unique()\n",
    "print(sum(Region_Severity_df['Pr(Ai)']))\n",
    "sum_accidents = sum(Region_Severity_df['Pr(Ai)'])\n",
    "Region_Severity_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
