{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas_ods_reader import read_ods\n",
    "from  matplotlib.ticker import PercentFormatter\n",
    "import seaborn as sns\n",
    " \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    " \n",
    "from sklearn import set_config\n",
    "# set_config(display='diagram') # Để trực quan hóa pipeline\n",
    " \n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_excel('data/RTAs_2012_2018_Time_Series.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = pd.read_excel('data/Road Safety Data - Accidents 2019.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(959847, 32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df_1.append(df_2,ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.to_csv('data/RTAs_2012_2019_Time_Series.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://roadtraffic.dft.gov.uk/api/local-authorities/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1077383, 32)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/RTAs_2012_2019_Time_Series.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Accident_Index', 'Location_Easting_OSGR', 'Location_Northing_OSGR',\n",
       "       'Longitude', 'Latitude', 'Police_Force', 'Accident_Severity',\n",
       "       'Number_of_Vehicles', 'Number_of_Casualties', 'Date', 'Day_of_Week',\n",
       "       'Time', 'Local_Authority_(District)', 'Local_Authority_(Highway)',\n",
       "       '1st_Road_Class', '1st_Road_Number', 'Road_Type', 'Speed_limit',\n",
       "       'Junction_Detail', 'Junction_Control', '2nd_Road_Class',\n",
       "       '2nd_Road_Number', 'Pedestrian_Crossing-Human_Control',\n",
       "       'Pedestrian_Crossing-Physical_Facilities', 'Light_Conditions',\n",
       "       'Weather_Conditions', 'Road_Surface_Conditions',\n",
       "       'Special_Conditions_at_Site', 'Carriageway_Hazards',\n",
       "       'Urban_or_Rural_Area', 'Did_Police_Officer_Attend_Scene_of_Accident',\n",
       "       'LSOA_of_Accident_Location'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta bỏ bớt một số cột không cần dùng trong đồ án này"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Accident_Index','Location_Easting_OSGR', 'Location_Northing_OSGR','Longitude', 'Latitude', 'Police_Force', 'Local_Authority_(District)', '1st_Road_Number', '2nd_Road_Number', 'Did_Police_Officer_Attend_Scene_of_Accident',\n",
    "       'LSOA_of_Accident_Location'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.loc(lambda df: df['Date'] == '2012-01-01 00:00:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2012-01-01 00:00:00', '2012-01-02 00:00:00',\n",
       "       '2012-01-03 00:00:00', ..., '31/08/2019', '31/10/2019',\n",
       "       '31/12/2019'], dtype=object)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-152-84dac9fc18ba>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[df['Date'] == date]['Date'] = date[0:10]\n"
     ]
    }
   ],
   "source": [
    "for date in df['Date'].unique():\n",
    "    df[df['Date'] == date]['Date'] = date[0:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          2012-01-01 00:00:00 00:04:00\n",
       "1          2012-01-01 00:00:00 00:05:00\n",
       "2          2012-01-01 00:00:00 00:05:00\n",
       "3          2012-01-01 00:00:00 00:09:00\n",
       "4          2012-01-01 00:00:00 00:09:00\n",
       "                       ...             \n",
       "1077378             31/12/2019 23:42:00\n",
       "1077379             31/12/2019 23:45:00\n",
       "1077380             31/12/2019 23:45:00\n",
       "1077381             31/12/2019 23:50:00\n",
       "1077382             31/12/2019 23:53:00\n",
       "Length: 1077383, dtype: object"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Date'] + ' ' + df['Time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Accident_Severity', 'Number_of_Vehicles', 'Number_of_Casualties',\n",
       "       'Date', 'Day_of_Week', 'Time', 'Local_Authority_(Highway)',\n",
       "       '1st_Road_Class', 'Road_Type', 'Speed_limit', 'Junction_Detail',\n",
       "       'Junction_Control', '2nd_Road_Class',\n",
       "       'Pedestrian_Crossing-Human_Control',\n",
       "       'Pedestrian_Crossing-Physical_Facilities', 'Light_Conditions',\n",
       "       'Weather_Conditions', 'Road_Surface_Conditions',\n",
       "       'Special_Conditions_at_Site', 'Carriageway_Hazards',\n",
       "       'Urban_or_Rural_Area'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hiện tại một số cột đang có dạng số, nhưng thực ra là dạng categorical không có thứ tự, ta chuyển lại về chữ nhờ file `variable_lookup.xls` do chính phủ Anh cung cấp để dễ dàng hiểu dữ liệu và tìm insight hơn.\n",
    "\n",
    "Các cột này là: 'Accident_Severity', 'Local_Authority_(Highway)', '1st_Road_Class', 'Road_Type', 'Junction_Detail', 'Junction_Control', '2nd_Road_Class', 'Pedestrian_Crossing-Human_Control', 'Pedestrian_Crossing-Physical_Facilities', 'Light_Conditions', 'Weather_Conditions', 'Road_Surface_Conditions', 'Special_Conditions_at_Site', 'Carriageway_Hazards', \n",
    "\n",
    "Các cột dạng categorical có thứ tự: ta chuyển lại về chữ cho dataframe dùng để tìm insight, nhưng giữ nguyên cho dataframe dùng để huấn luyện model:\n",
    "\n",
    "'Day_of_Week', 'Urban_or_Rural_Area'\n",
    "\n",
    "Tuy nhiên, ta thấy cột 'Local_Authority_(Highway)' có đến 208 giá trị, ta sẽ chuyển các vùng địa phương này thành khu vực (region) nó phụ thuộc vào, để nghiến cứu trên phạm vi lớn hơn, ta có thể chuyển nhờ API sau:\n",
    "\n",
    "https://roadtraffic.dft.gov.uk/api/local-authorities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "unordered_cate_cols = ['Road_Type', 'Junction_Detail', \n",
    "                'Junction_Control', 'Pedestrian_Crossing-Human_Control', \n",
    "                'Pedestrian_Crossing-Physical_Facilities',\n",
    "                'Special_Conditions_at_Site', 'Carriageway_Hazards']\n",
    "        \n",
    "ordered_cate_cols = ['Accident_Severity', 'Day_of_Week', '1st_Road_Class',\n",
    "                             '2nd_Road_Class', 'Light_Conditions', 'Weather_Conditions',\n",
    "                             'Road_Surface_Conditions', 'Urban_or_Rural_Area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColMap(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, mode = 'insight'):\n",
    "#         mode = `insight` or `trainning`\n",
    "        self.mode = mode\n",
    "        pass\n",
    "    def fit(self, X_df, y=None):\n",
    "        return self\n",
    "    def transform(self, X_df, y=None):\n",
    "        tf_df = X_df.copy()\n",
    "        \n",
    "        # Bước 1. Map\n",
    "        \n",
    "        if self.mode == 'trainning' or self.mode == 'insight':\n",
    "            \n",
    "            for col in unordered_cate_cols:\n",
    "                if col == 'Pedestrian_Crossing-Human_Control':\n",
    "                    name = 'Ped Cross - Human'\n",
    "                elif col == 'Pedestrian_Crossing-Physical_Facilities':\n",
    "                    name = 'Ped Cross - Physical'\n",
    "                elif col == 'Urban_or_Rural_Area':\n",
    "                    name = 'Urban Rural'\n",
    "                else:\n",
    "                    name = col.replace('_',' ')\n",
    "                    \n",
    "                map_df = pd.read_excel('data/variable_lookup.xls',name)\n",
    "                for code in map_df['code']:\n",
    "                    tf_df[col] = tf_df[col].replace(code,map_df[map_df['code'] == code]['label'].values[0])\n",
    "                    \n",
    "        if self.mode == 'insight':\n",
    "            for col in ordered_cate_cols:\n",
    "                if col == 'Weather_Conditions':\n",
    "                    name = 'Weather'\n",
    "                elif col == 'Road_Surface_Conditions':\n",
    "                    name = 'Road Surface'\n",
    "                else:\n",
    "                    name = col.replace('_',' ')\n",
    "                    \n",
    "                map_df = pd.read_excel('data/variable_lookup.xls',name)\n",
    "                for code in map_df['code']:\n",
    "                    tf_df[col] = tf_df[col].replace(code,map_df[map_df['code'] == code]['label'].values[0])\n",
    "                    \n",
    "        # Bước 2. Xử lý date time\n",
    "        \n",
    "        #if Ons code has not exist yet\n",
    "        tf_df['Ons code'] = np.nan\n",
    "        ##\n",
    "        \n",
    "        tf_df = tf_df.drop(['Ons code', 'Accident severity', 'Accident year'], axis=1)\n",
    "        \n",
    "        # Bước 2\n",
    "        tf_df['Junction type'] = tf_df['Junction type'].replace('Unknown', np.nan)\n",
    "        tf_df['Speed limit'] = tf_df['Speed limit'].replace('Unknown', np.nan)\n",
    "        \n",
    "        # Bước 3\n",
    "        tf_df = tf_df.dropna(axis = 0, thresh = 3)\n",
    "        tf_df = tf_df.dropna(axis = 1, how = 'all')\n",
    "        return tf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_indices = {name: i for i, name in enumerate(df.columns)}\n",
    "\n",
    "n = len(df)\n",
    "train_df = df[0:int(n*0.7)]\n",
    "val_df = df[int(n*0.7):int(n*0.9)]\n",
    "test_df = df[int(n*0.9):]\n",
    "\n",
    "num_features = df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "contigency_df = pd.crosstab(df_1['Local_Authority_(District)'], df_1['Accident_Severity'])\n",
    "contigency_df.columns = ['1','2','3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Local_Authority_(District)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51</td>\n",
       "      <td>1526</td>\n",
       "      <td>10916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>845</td>\n",
       "      <td>6132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>806</td>\n",
       "      <td>5568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37</td>\n",
       "      <td>873</td>\n",
       "      <td>6082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>40</td>\n",
       "      <td>971</td>\n",
       "      <td>7496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>33</td>\n",
       "      <td>276</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>77</td>\n",
       "      <td>542</td>\n",
       "      <td>2829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>39</td>\n",
       "      <td>335</td>\n",
       "      <td>1008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>38</td>\n",
       "      <td>353</td>\n",
       "      <td>2209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>10</td>\n",
       "      <td>37</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>380 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             1     2      3\n",
       "Local_Authority_(District)                 \n",
       "1                           51  1526  10916\n",
       "2                           32   845   6132\n",
       "3                           16   806   5568\n",
       "4                           37   873   6082\n",
       "5                           40   971   7496\n",
       "...                         ..   ...    ...\n",
       "937                         33   276   1080\n",
       "938                         77   542   2829\n",
       "939                         39   335   1008\n",
       "940                         38   353   2209\n",
       "941                         10    37    159\n",
       "\n",
       "[380 rows x 3 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print((sum(contigency_df['1']) + sum(contigency_df['2']) + sum(contigency_df['3'])) == df_1.shape[0])\n",
    "contigency_df\n",
    "# df_1.shape\n",
    "# contigency_df.xs('Accident_Severity', level='1', axis=1)\n",
    "# items_df_preprocessed[df_1['Region'] == f'{region}'].groupby('Accident severity')['Accidents'].agg(sum).reset_index(name='Value count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Region_Severity_df = pd.DataFrame({'Region' : [np.nan],'Fatal' : [np.nan],'Serious' : [np.nan],'Slight' : [np.nan], 'Pr(Ai)': [np.nan]})\n",
    "\n",
    "for region in df_1['LSOA_of_Accident_Location'].unique():\n",
    "    x = items_df_preprocessed[df_1['Region'] == f'{region}'].groupby('Accident severity')['Accidents'].agg(sum).reset_index(name='Value count')\n",
    "    y = np.array(x['Value count'])\n",
    "  # y = np.insert(y, 0, 3, axis=0)\n",
    "  # source: https://stackoverflow.com/a/58293212\n",
    "    data_to_append = {}\n",
    "    for i in range(len(Region_Severity_df.columns)):\n",
    "        if(i>=1 and i !=4):\n",
    "            data_to_append[Region_Severity_df.columns[i]] = y[i-1]\n",
    "        elif (i == 4):\n",
    "            data_to_append[Region_Severity_df.columns[i]] = sum(y)\n",
    "            \n",
    "    Region_Severity_df = Region_Severity_df.append(data_to_append, ignore_index = True)\n",
    "\n",
    "Region_Severity_df = Region_Severity_df.drop(0,0)\n",
    "Region_Severity_df['Region'] = RTAs_region_year_df['Region'].unique()\n",
    "print(sum(Region_Severity_df['Pr(Ai)']))\n",
    "sum_accidents = sum(Region_Severity_df['Pr(Ai)'])\n",
    "Region_Severity_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
