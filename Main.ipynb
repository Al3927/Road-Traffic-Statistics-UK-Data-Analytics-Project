{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font size =\"9\"> ĐỒ ÁN MÔN HỌC CUỐI KÌ</font></center>\n",
    " <br />\n",
    " \n",
    "__TÊN MÔN HỌC:__ PHÂN TÍCH DỮ LIỆU THÔNG MINH\n",
    "\n",
    "__ĐỀ TÀI:__ PHÂN TÍCH DỮ LIỆU TAI NẠN ĐƯỜNG BỘ TẠI CÁC VÙNG CỦA NƯỚC ANH\n",
    "\n",
    "__GIẢNG VIÊN:__ DƯƠNG NGUYỄN THÁI BẢO\n",
    " \n",
    "__THỨ TỰ NHÓM:__ 07\n",
    " \n",
    "__THÀNH VIÊN:__\n",
    "\n",
    "- 18120655 Phạm Minh Vương \n",
    "- 18120568 Phạm Văn Thật \n",
    "- 18120184 Nguyễn Nguyên Khang \n",
    "- 1712431 Bùi Lê Hiếu \n",
    "- 1712072 Nguyễn Văn Khoa\n",
    "\n",
    "__PHÂN CÔNG:__\n",
    "\n",
    "Công việc | Thực hiện | Mức độ hoàn thành\n",
    "------------ | ------------- | ------------\n",
    "Thu thập dữ liệu | Khang | 100%\n",
    "Khám phá dữ liệu cơ bản | Khang | 100%\n",
    "Tiền xử lý dữ liệu | Khang | 100%\n",
    "Mô hình hóa dữ liệu | Khang | 100%\n",
    "Khám phá Insight 1,2|  | 100%\n",
    "Khám phá Insight 3,4|  | 100%\n",
    "Khám phá Insight 5,6|  | 100%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## <center><font size =\"7\"> Idea( khi nào nộp xóa)</font></center>\n",
    "\n",
    "Association rules\n",
    "\n",
    "Kiểm định giả thuyết thống kê\n",
    "\n",
    "Clustering: Region\n",
    "\n",
    "[IV.3. Phân bố giá trị của cột có kiểu dữ liệu không phải dạng số](#3.-Phân-bố-giá-trị-của-cột-có-kiểu-dữ-liệu-không-phải-dạng-số)\n",
    "\n",
    "[Paper](https://scholar.google.com/scholar?q=%22data%20gov%20uk%20dataset%20cb7ae6f0%204be6%204935%209277%2047e5ce24a11f%20road%20safety%20data%22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>\n",
    "\n",
    "## <center><font size =\"7\"> Mục lục</font></center>\n",
    " <br />\n",
    " \n",
    "- [Giới thiệu đồ án](#I.-Giới-thiệu-đồ-án)\n",
    "   - [Dữ liệu](#1.-Dữ-liệu)\n",
    "   - [Câu hỏi](#2.-Câu-hỏi)\n",
    "- [Thu thập dữ liệu](#II.-Thu-thập-dữ-liệu)\n",
    "- [Khám phá dữ liệu, tiền xử lý đơn giản và tách tập](#III.-Khám-phá-dữ-liệu,-tiền-xử-lý-đơn-giản-và-tách-tập)\n",
    "  - [Kiểm tra output hợp lệ](#1.-Kiểm-tra-output-hợp-lệ)\n",
    "  - [Ý nghĩa của mỗi dòng](#2.-Ý-nghĩa-của-mỗi-dòng)\n",
    "  - [Kiểm tra các giá trị trùng](#3.-Kiểm-tra-các-giá-trị-trùng)   \n",
    "  - [Kiểm tra các giá trị không hợp lệ](#4.-Kiểm-tra-các-giá-trị-không-hợp-lệ)\n",
    "  - [Xử lý dữ liệu bị lệch](#5.-Xử-lý-dữ-liệu-bị-lệch)\n",
    "  - [Tách các tập](#6.-Tách-các-tập) \n",
    "- [Khám phá dữ liệu (tập huấn luyện)](#IV.-Khám-phá-dữ-liệu-(tập-huấn-luyện))\n",
    "  - [Kiểm tra kiểu dữ liệu của input có phù hợp](#1.-Kiểm-tra-kiểu-dữ-liệu-của-input-có-phù-hợp)\n",
    "  - [Phân bố giá trị của cột có kiểu dữ liệu dạng số](#2.-Phân-bố-giá-trị-của-cột-có-kiểu-dữ-liệu-dạng-số)\n",
    "  - [Phân bố giá trị của cột có kiểu dữ liệu không phải dạng số](#3.-Phân-bố-giá-trị-của-cột-có-kiểu-dữ-liệu-không-phải-dạng-số)\n",
    "- [Tiền xử lý (tập huấn luyện)](#V.-Tiền-xử-lý-(tập-huấn-luyện))\n",
    "  - [Bỏ cột](#1.-Bỏ-cột)\n",
    "  - [Sửa cột](#2.-Sửa-cột)\n",
    "  - [Xử lý giá trị thiếu](#3.-Xử-lý-giá-trị-thiếu)\n",
    "  - [Chuẩn hóa](#4.-Chuẩn-hóa)\n",
    "  - [Tạo pipeline](#5.-Tạo-pipeline)\n",
    "- [Mô hình hóa dữ liệu](#VI.-Mô-hình-hóa-dữ-liệu)\n",
    "  - [Tìm mô hình tốt nhất](#1.-Tìm-mô-hình-tốt-nhất)\n",
    "  - [Đánh giá mô hình tìm được](#2.-Đánh-giá-mô-hình-tìm-được)\n",
    "- [Nhìn lại quá trình làm đồ án](#VII.-Nhìn-lại-quá-trình-làm-đồ-án)\n",
    "  - [Khó khăn](#1.-Khó-khăn)\n",
    "  - [Những thứ học được](#2.-Những-thứ-học-được)\n",
    "  - [Những điều cần bổ sung nếu có thêm thời gian](#3.-Những-điều-cần-bổ-sung-nếu-có-thêm-thời-gian)\n",
    "- [Tài liệu tham khảo](#VIII.-Tài-liệu-tham-khảo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>\n",
    "\n",
    "## I. Giới thiệu đồ án\n",
    "\n",
    "Mục đích chính của đồ án là phân tích dữ liệu tai nạn đường bộ tại các vùng của nước Anh, tìm ra các insight quan trọng, đưa ra giải pháp giúp giảm thiểu tai nạn\n",
    "\n",
    "### 1. Dữ liệu\n",
    "\n",
    "<center><img src=\"data/data.png\"\n",
    "     alt=\"data\"\n",
    "     style=\"float: center; margin-right: 10px;\" \n",
    "     width=\"600\" height=\"300\"/></center></br>\n",
    "\n",
    "Tập dữ liệu: Tai nạn đường bộ tại các vùng của nước Anh\n",
    "\n",
    "Tập dữ liệu được tải về từ [Road traffic open data](https://roadtraffic.dft.gov.uk/custom-downloads)\n",
    "\n",
    "Dữ liệu đúng và hợp pháp vì được cung cấp bởi trang web chính thức của chính phủ Anh, có đuôi gov.uk\n",
    "\n",
    "### 2. Câu hỏi\n",
    "\n",
    "Làm sao để giảm thiểu tai nạn tại nước Anh? \n",
    "\n",
    "Ta sử dụng mô hình học máy\n",
    "\n",
    "*Output - số lượng tai nạn -* được tính từ *input - thông tin của các vụ tai nạn -* theo công thức nào?\n",
    "\n",
    "Do Input ở đây là các thông tin mà con người có tể điều chỉnh được, nên ta hy vọng nhờ vào học máy, tìm ra được mối liên hệ tin cậy giữa input và output, giúp nhận ra và điều chỉnh input để giảm thiểu số lượng tại nạn.\n",
    "\n",
    "- Chia tập: \n",
    "\n",
    "Hồi quy:\n",
    "\n",
    "2012 - 2017 : Training set\n",
    "\n",
    "2018 - 2019: Testing set\n",
    "\n",
    "Keras stateful LSTM model và Facebook Prophet model: \n",
    "\n",
    "2017 - 2018 : Training set\n",
    "\n",
    "2019: Testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pandas_ods_reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas_ods_reader import read_ods\n",
    "from  matplotlib.ticker import PercentFormatter\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "from sklearn import set_config\n",
    "set_config(display='diagram') # Để trực quan hóa pipeline\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Set Option\n",
    "pd.set_option('max_colwidth', 10000)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Thu thập dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Khám phá dữ liệu, tiền xử lý đơn giản và tách tập"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đầu tiên ta sẽ đọc file dữ liệu vào DataFrame sau đó sẽ khám phá dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_df = read_ods('data/a4360ffb-8320-4178-9adf-bcd92f5870b5.ods', 'Regions - By severity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Ý nghĩa của mỗi dòng\n",
    "Quan sát sơ bộ dữ liệu và qua quá trình thu thập dữ liệu, ta thấy mỗi dòng chứa thông tin của một hoặc nhiều vụ tai nạn, và không có vấn đề các dòng có ý nghĩa khác nhau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Kiểm tra các giá trị trùng\n",
    "Ta xem thử có bao nhiêu mẫu bị trùng giá trị"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_duplicated_rows = items_df.duplicated().sum()\n",
    "num_duplicated_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xóa các mẫu có giá trị trùng bằng phương thức drop_duplicates của pandas, mặc định giữ lại dòng có giá trị lặp đầu tiên"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_df = items_df.drop_duplicates(ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Kiểm tra các giá trị không hợp lệ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta kiểm tra các trường hợp:\n",
    "\n",
    "1. Accident year < 0 hoặc > 2019\n",
    "\n",
    "2. Accidents < 1\n",
    "\n",
    "3. Accident year và Accidents có phần thập phân khác 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xem xét trường hợp 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_Accident_year = (items_df['Accident year'] < 0) | (items_df['Accident year'] > 2019)\n",
    "invalid_Accident_year_vals = invalid_Accident_year.sum()\n",
    "invalid_Accident_year_vals/len(items_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xem xét trường hợp 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_Accidents = (items_df['Accidents'] < 1)\n",
    "invalid_Accidents_vals = invalid_Accidents.sum()\n",
    "invalid_Accidents_vals/len(items_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xem xét trường hợp 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_Numeric_Type = (((items_df['Accidents'] - items_df['Accidents'].apply(np.ceil)) != 0) | ((items_df['Accident year'] - items_df['Accident year'].apply(np.ceil)) != 0) )\n",
    "invalid_Numeric_Type_vals = invalid_Numeric_Type.sum()\n",
    "invalid_Numeric_Type_vals/len(items_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xử lý 3 trường hợp trên: \n",
    "\n",
    "Lưu ý rằng dù không có lỗi trong các trường hợp này nhưng ta không biết dữ liệu mới thế nào, nên ta vẫn bỏ tất cả các dòng bị lỗi (nếu có):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_df = items_df[~invalid_Accident_year]\n",
    "items_df = items_df[~invalid_Accidents]\n",
    "items_df = items_df[~invalid_Numeric_Type]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Tách các tập\n",
    "Vậy là dữ liệu đã sẵn sàng để tách và khám phá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tách X và y\n",
    "y_sr = items_df[\"Accidents\"]\n",
    "X_df = items_df.drop(\"Accidents\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tách train và test\n",
    "rest_X_df, test_X_df, rest_y_sr, test_y_sr = train_test_split(X_df, y_sr, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tách train và validation\n",
    "train_X_df, val_X_df, train_y_sr, val_y_sr = train_test_split(rest_X_df, rest_y_sr, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_sr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_X_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_y_sr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y_sr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Khám phá dữ liệu (tập huấn luyện)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Kiểm tra kiểu dữ liệu của input có phù hợp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta thấy kiểu dữ liệu của input đã phù hợp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Phân bố giá trị của cột có kiểu dữ liệu dạng số"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tỉ lệ % (từ 0 đến 100) các giá trị thiếu \n",
    "- Giá trị min\n",
    "- Giá trị lower quartile (phân vị 25)\n",
    "- Giá trị median (phân vị 50)\n",
    "- Giá trị upper quartile (phân vị 75)\n",
    "- Giá trị max\n",
    "\n",
    "Kết quả được lưu vào DataFrame `num_col_info_df`, trong đó: \n",
    "- Tên của các cột là tên của các cột số trong `train_X_df` và output `Accidents`\n",
    "- Tên của các dòng là: \"missing_ratio\", \"min\", \"lower_quartile\", \"median\", \"upper_quartile\", \"max\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_ratio(df):\n",
    "    return (df.isna().mean() * 100).round(1)\n",
    "def lower_quartile(df):\n",
    "    return df.quantile(0.25)\n",
    "def median(df):\n",
    "    return df.quantile(0.5)\n",
    "def upper_quartile(df):\n",
    "    return df.quantile(0.75)\n",
    "num_df = train_X_df.select_dtypes(exclude='object').copy()\n",
    "num_df['Accidents'] = train_y_sr.copy()\n",
    "num_col_info_df = num_df.agg([missing_ratio, min, lower_quartile, median, upper_quartile, max]).round(1)\n",
    "num_col_info_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nhận xét: \n",
    "1. Không có thuộc tính nào bị thiếu\n",
    "2. Output có vẻ lệch trái, ta sẽ kiểm tra ở các bước sau."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Phân bố giá trị của cột có kiểu dữ liệu không phải dạng số"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tỉ lệ % (từ 0 đến 100) các giá trị thiếu \n",
    "\n",
    "- Số lượng các giá trị (các giá trị ở đây là các giá trị khác nhau và ta không xét giá trị thiếu)\n",
    "\n",
    "- Tỉ lệ % (từ 0 đến 100) của mỗi giá trị được sort theo tỉ lệ % giảm dần (ta không xét giá trị thiếu, tỉ lệ là tỉ lệ so với số lượng các giá trị không thiếu): dùng dictionary để lưu, key là giá trị, value là tỉ lệ %\n",
    "\n",
    "Kết quả được lưu vào DataFrame `cat_col_info_df`, trong đó: \n",
    "\n",
    "- Tên của các cột là tên của các cột không phải số trong `train_X_df`\n",
    "- Tên của các dòng là: \"missing_ratio\", \"num_values\", \"value_ratios\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_ratio(df):\n",
    "    return (df.isna().mean() * 100).round(1)\n",
    "def num_values(df):\n",
    "    return df.nunique()\n",
    "def value_ratios(c):\n",
    "    return dict((c.value_counts(normalize=True) * 100).round(1))\n",
    "df = train_X_df.select_dtypes(include='object')\n",
    "cat_col_info_df = df.agg([missing_ratio, num_values, value_ratios])\n",
    "cat_col_info_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta có thể thấy, trong 8 năm từ năm 2012 đến 2019:\n",
    "\n",
    "1. Đa phần `tai nạn nhẹ` với 59.2%, `tai nạn gây chết người` chỉ chiếm 8.7%\n",
    "2. Số lượng tại nạn ở các vùng là tương tự nhau, trừ `South East` cao nhất chiếm đến 12.3% trong 11 vùng, và hai vùng `North East` chỉ 6.4% cùng `Wales` chỉ chiếm 6.2% là hai vùng có số lượng tai nạn thấp nhất. Có lẽ ta cần phân tích kỹ vào hai vùng này để tìm cách giảm lượng tai nạn.\n",
    "3. Tai nạn lại thường xảy ra nhiều ở tốc độ giới hạn `21-30 mph` với 36.1%, trong khi tốc độ giới hạn cao nhất là `61-70 mph` chỉ chiếm 5.1% các vụ tai nạn. Ta thấy có giá trị thiếu ở cột `Speed limit` được thể hiện bằng chuỗi `Unknown`, và chỉ chiếm 0.1%, nên ta có thể điền giá trị thiếu sau.\n",
    "4. `Road class A` thường xuyên xảy ra các vụ tai nạn nhất, với 40% các vụ tai nạn xảy ra ở road class này. Trong khi `Road Class: Mortorway` và `A(M)` chỉ chiếm 3.15% và 1.0% trong số các vụ tai nạn, đây có lẽ là hai road class ta cần hường tới để giảm thiểu tai nạn.\n",
    "5. `Single carriageway`: Đường đơn (đường hai chiều) là nơi thường xuyên xảy ra tai nạn với 42.8% các vụ tai nạn xảy ra ở đây. `Slip road` chỉ chiếm 8.2% và `Unknown road` 5.7% Ta có thể xem `Unknown` không là một giá trị thiếu vì nó chiếm đến 5.7% và có thể có ý nghĩa riêng.\n",
    "6. `Not at junction or within 20 metres` chiếm phần trăm cao nhất: 23% trong `Junction type`, `Mini-roundabout` chỉ chiếm 4.4% và `Unknown` 0.5% là hai giá trị chiếm phần trăm thấp nhất trong cột này. Với 0.5%, ta xem Unknow là một giá trị thiếu và sẽ điền sau. \n",
    "7. Ta có thể xem xét đề ra một số biện pháp như đặt các biển báo nguy hiểm nổi bật ở những nơi giao nhau nguy hiểm, nếu có nhiều lựa chọn xây dựng nên chọn loại ít xảy ra tai nạn hơn,...\n",
    "\n",
    "Các nhận xét trên đưa ra cho ta một cái nhìn tổng quát, tuy nhiên ta cần đi phân tích sâu hơn để biết rằng các vụ tai nạn biến đổi như thế nào theo thời gian, và là tai nạn chết người, nghiêm trọng, hay nhẹ để đánh giá đúng hơn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Tiền xử lý (tập huấn luyện)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Bỏ cột\n",
    "\n",
    "Ta sẽ tiến hành bỏ những cột sau:\n",
    "\n",
    " - Bỏ cột `Ons Code`: Cột này tương đương với cột `Region`, có thể dùng để get API thông tin về Region đó như tổng số lượng phương tiện vào các năm, tuy nhiên, các thông số đó không cần thiết trong đồ án này, nên ta bỏ cột `Ons Code`\n",
    " - Bỏ cột `Accident severity`: Mục đích của ta khi huấn luyện model là tìm mối tương quan giữa số vụ tai nạn, và các thuộc tính con người có thể thay đổi được, `Accident severity` không nằm trong nhóm này, thậm chí nó có thể dùng làm output cho một bài toán huấn luyện model khác, nên ta bỏ cột."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Chuyển `Unknown` ở một số cột thành np.nan\n",
    "\n",
    "Như đã phân tích ở [IV.3. Phân bố giá trị của cột có kiểu dữ liệu không phải dạng số](#3.-Phân-bố-giá-trị-của-cột-có-kiểu-dữ-liệu-không-phải-dạng-số) ta đổi `Unknown` thành np.nan ở các cột `Junction type` và `Speed limit`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Bỏ các dòng có trên 3 giá trị thiếu, và các cột thiếu tất cả các giá trị\n",
    "\n",
    "Tuy data của chúng ta hiện không có giá trị thiếu, nhưng ta không biết data mới có bị thiếu hay không, hoặc sau khi chuyển `Unknown` ở một số cột thành np.nan, giá trị thiếu ở một dòng quá nhiều, nên ta sẽ bỏ các dòng có trên 3 giá trị thiếu, và các cột thiếu tất cả các giá trị\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class ColAdderDropper sẽ thực hiện các bước trên:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColAdderDropper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, X_df, y=None):\n",
    "        return self\n",
    "    def transform(self, X_df, y=None):\n",
    "        tf_df = X_df.copy()\n",
    "        \n",
    "        # Bước 1\n",
    "        \n",
    "        #if Ons code has not exist yet\n",
    "        tf_df['Ons code'] = np.nan\n",
    "        ##\n",
    "        \n",
    "        tf_df = tf_df.drop(['Ons code', 'Accident severity', 'Accident year'], axis=1)\n",
    "        \n",
    "        # Bước 2\n",
    "        tf_df['Junction type'] = tf_df['Junction type'].replace('Unknown', np.nan)\n",
    "        tf_df['Speed limit'] = tf_df['Speed limit'].replace('Unknown', np.nan)\n",
    "        \n",
    "        # Bước 3\n",
    "        tf_df = tf_df.dropna(axis = 0, thresh = 3)\n",
    "        tf_df = tf_df.dropna(axis = 1, how = 'all')\n",
    "        return tf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColAdderDropperInsight(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, X_df, y=None):\n",
    "        return self\n",
    "    def transform(self, X_df, y=None):\n",
    "        tf_df = X_df.copy()\n",
    "        \n",
    "        # Bước 1\n",
    "        \n",
    "        #if Ons code has not exist yet\n",
    "        tf_df['Ons code'] = np.nan\n",
    "        ##\n",
    "        \n",
    "        tf_df = tf_df.drop(['Ons code'], axis=1)\n",
    "        \n",
    "        # Bước 2\n",
    "        tf_df['Junction type'] = tf_df['Junction type'].replace('Unknown', np.nan)\n",
    "        tf_df['Speed limit'] = tf_df['Speed limit'].replace('Unknown', np.nan)\n",
    "        \n",
    "        # Bước 3\n",
    "        tf_df = tf_df.dropna(axis = 0, thresh = 3)\n",
    "        tf_df = tf_df.dropna(axis = 1, how = 'all')\n",
    "        return tf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "col_adderdropper = ColAdderDropper()\n",
    "fewer_cols_train_X_df = col_adderdropper.fit_transform(train_X_df)\n",
    "fewer_cols_train_X_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fewer_cols_train_X_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Xử lý giá trị thiếu\n",
    "\n",
    "- Với các thuộc tính bị thiếu toàn bộ dữ liệu, các mẫu bị thiếu từ 15 thuộc tính ta đã xử lý ở class ColAdderDropper phía trên bằng 2 dòng lệnh sau:\n",
    "```python\n",
    "tf_df = tf_df.dropna(axis = 0, thresh = 15)\n",
    "tf_df = tf_df.dropna(axis = 1, how = 'all')\n",
    "```\n",
    "- Với các cột dạng số, ta sẽ điền giá trị thiếu bằng giá trị mean của cột <font color=gray>(dùng `SimpleImputer` trong Sklearn)</font>. Với *tất cả* các cột dạng số trong tập huấn luyện, ta đều cần tính mean, vì ta không biết được cột nào sẽ bị thiếu giá trị khi dự đoán với các véc-tơ input mới. \n",
    "\n",
    "- Với các cột không phải dạng số và không có thứ tự:\n",
    "\n",
    "    - Ta sẽ điền giá trị thiếu bằng giá trị mode (giá trị xuất hiện nhiều nhất) của cột <font color=gray>(dùng `SimpleImputer` trong Sklearn)</font>. Với *tất cả* các cột không có dạng số và không có thứ tự, ta đều cần tính mode, vì ta không biết được cột nào sẽ bị thiếu giá trị khi dự đoán với các véc-tơ input mới.\n",
    "    - Sau đó, ta sẽ chuyển sang dạng số bằng phương pháp mã hóa one-hot <font color=gray>(dùng `OneHotEncoder` trong Sklearn, tham số `handle_unknown` = 'ignore' vì khi dự đoán với các véc-tơ input mới ta không biết được cột nào sẽ bị thiếu giá trị)</font>.\n",
    "\n",
    "\n",
    "- Với cột không phải dạng số và có thứ tự:\n",
    "\n",
    "    - Data của ta không có cột dạng này, kể cả cột `Speed limit` do có giá trị `Motorway` nên không là cột có thứ tự"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_col = ['Accident year']\n",
    "nume_cols = ['Accident year']\n",
    "unorder_cate_cols = ['Region', 'Speed limit', 'Road class', 'Road type', 'Junction type']\n",
    "unorder_cate_cols_Insight = ['Region', 'Speed limit', 'Road class', 'Road type', 'Junction type', 'Accident severity']\n",
    "# order_cate_cols = ['']\n",
    "\n",
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp_mode = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "unorder_cate_pipeline = make_pipeline(imp_mode, enc)\n",
    "column_transformer = ColumnTransformer(transformers = [('unorder_categorical', unorder_cate_pipeline, unorder_cate_cols)], remainder='passthrough')\n",
    "\n",
    "column_transformer_for_find_Insight = ColumnTransformer(transformers = [('numerical', imp_mean, nume_cols),\n",
    "                                                                        ('unorder_categorical', imp_mode, unorder_cate_cols_Insight),\n",
    "                                                                        ('y',imp_mean,['Accidents'])], remainder='passthrough')\n",
    "#('order_categorical', imp_mode, order_cate_cols)\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Chuẩn hóa\n",
    "Cuối cùng, khi tất cả các cột đã được điền giá trị thiếu và đã có dạng số, ta sẽ tiến hành chuẩn hóa bằng cách trừ đi mean và chia cho độ lệch chuẩn của cột để giúp cho một số thuật toán như PCA, T-SNE,... chạy chính xác"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Tạo pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess_pipeline = make_pipeline(ColAdderDropper(), column_transformer, StandardScaler(with_mean=False))\n",
    "preprocess_pipeline = make_pipeline(ColAdderDropper(), column_transformer)\n",
    "preprocess_pipeline_Insight = make_pipeline(ColAdderDropperInsight(), column_transformer_for_find_Insight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_train_X = preprocess_pipeline.fit_transform(train_X_df)\n",
    "preprocessed_val_X = preprocess_pipeline.transform(val_X_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_val_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Xem covariance matrix (Vẽ cho biết, khi nào nộp xóa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_for_cov_df = train_X_df.copy()\n",
    "x_for_cov_df['Accidents'] = train_y_sr.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_for_cov = preprocess_pipeline.fit_transform(x_for_cov_df)\n",
    "x_for_cov = x_for_cov.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_mat =np.cov(x_for_cov.T)\n",
    "plt.figure(figsize=(30,30))\n",
    "sns.set(font_scale=1.5)\n",
    "hm = sns.heatmap(cov_mat,\n",
    "                 cbar=True,\n",
    "                 annot=True,\n",
    "                 square=True,\n",
    "                 linewidths=.5,\n",
    "                 fmt='.2f',\n",
    "                 yticklabels=x_for_cov_df.columns,\n",
    "                 xticklabels=x_for_cov_df.columns)\n",
    "plt.title('Covariance matrix showing correlation coefficients')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI. Mô hình hóa dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Tìm mô hình tốt nhất\n",
    "\n",
    "Do output là kiểu số thực liên tục nên ta sẽ sử dụng mô hình hồi quy để dự đoán các input mới, ta sẽ sử dụng model sau:\n",
    "\n",
    "- Hồi quy tuyến tính bằng máy học\n",
    "- Hồi quy tuyến tính bằng toán thống kê\n",
    "- Keras stateful LSTM model\n",
    "- Facebook Prophet model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đầu tiên, đối với các mô hình hồi quy này thì ta sử dụng độ đo $R^2$ để đánh giá độ lỗi vì độ đo MSE không cho ta biết được cụ thể chất lượng của mô hình \n",
    "\n",
    "$R^2$ cho biết độ phù hợp của mô hình, người ta nghiên cứu được rằng, với $R^2$ > 0.5 thì một mô hình được đánh giá là phù hợp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Huấn luyện mô hình hồi quy tuyến tính "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_full_pipeline = make_pipeline(ColAdderDropper(), column_transformer, StandardScaler(with_mean=False), LinearRegression())\n",
    "linear_full_pipeline.fit(train_X_df, train_y_sr);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R^2 tập validation\n",
    "linear_full_pipeline.score(val_X_df, val_y_sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score < 0.5, **không** thỏa tiêu chí đặt ra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tham khảo\n",
    "\n",
    "https://www.researchgate.net/profile/Mingchen-Feng/publication/341665300_Towards_Big_Data_Analytics_and_Mining_for_UK_Traffic_Accident_Analysis_Visualization_Prediction/links/5ed119a7299bf1c67d272293/Towards-Big-Data-Analytics-and-Mining-for-UK-Traffic-Accident-Analysis-Visualization-Prediction.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Kiểm tra output hợp lệ ( sau khi chia train/ttest)\n",
    "\n",
    "Ta kiểm tra xem dữ liệu thu được có đủ điều kiện để mô hình hóa hay không? Vì đây là bài toán hồi qui nên cột output bắt buộc phải có dạng số; nếu hiện chưa có dạng số (ví dụ, số nhưng được lưu dưới dạng chuỗi) thì ta cần chuyển sang dạng số rồi mới tách các tập"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xem phân bố các giá trị của output\n",
    "items_df['Accidents'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accidents_df = items_df['Accidents'].value_counts().rename_axis('Accidents').reset_index(name='Frequency')\n",
    "Accidents_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axis([1, 15, 0, 16211])\n",
    "sns.lineplot(data = Accidents_df, x = 'Accidents', y = 'Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_skew(df, column, s=0.6):\n",
    "    k = df.copy()\n",
    "    while (np.log(k[column] + 1).skew() > s):\n",
    "        vc = k[column].value_counts()\n",
    "        mf = vc.index[0]\n",
    "        if len(vc[vc < vc[0]]):\n",
    "            sf_n = vc[vc < vc[0]].iloc[0]\n",
    "        else:\n",
    "            break\n",
    "        mf_sample = k[k[column] == mf]\n",
    "        not_mf_sample = k[k[column] != mf]\n",
    "        undersampled = resample(mf_sample, replace = False,\n",
    "                                    n_samples = sf_n, random_state = 0)\n",
    "        k = pd.concat([undersampled, not_mf_sample])\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_df = num_df.reset_index()\n",
    "num_df = num_df.drop(['index'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = reduce_skew(num_df, 'Accidents', 0.9)\n",
    "# x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VII. Phân tích Dữ Liệu Tìm Insight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_df_preprocessed = preprocess_pipeline_Insight.fit_transform(items_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_df_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_df_preprocessed = pd.DataFrame(items_df_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = nume_cols + unorder_cate_cols_Insight + ['Accidents']\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_df_preprocessed.columns = columns\n",
    "items_df_preprocessed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
